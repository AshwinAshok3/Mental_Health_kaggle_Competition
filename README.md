<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            color: #333;
            padding: 20px;
        }
        h1, h2 {
            color: #2E86C1;
        }
        ul {
            list-style-type: none;
            padding-left: 0;
        }
        li {
            margin: 5px 0;
        }
        .emoji {
            font-size: 1.2em;
        }
        .highlight {
            color: #1F618D;
            font-weight: bold;
        }
        .note {
            font-style: italic;
            color: #566573;
        }
        a {
            color: #2980B9;
            text-decoration: none;
        }
    </style>
</head>
<h1>Details About the Project</h1>
  
<body>

  <h1 class="emoji">🧠 Mental Health Data Prediction – Kaggle Competition 🎯</h1>

  <h2 class="emoji">🚀 Introduction</h2>
  <p>Predicting mental health trends with <span class="highlight">AI-driven models</span> is a critical challenge in today's world. This project tackles that challenge using a <span class="highlight">large-scale dataset</span> from the 
      <a href="https://www.kaggle.com/competitions/playground-series-s4e11/data">Kaggle Mental Health Competition</a>, which contains <b>140,000+ records</b>.
  </p>

  <p>Through rigorous <b>data preprocessing</b>, <b>feature selection</b>, and <b>deep learning techniques</b>, I successfully developed an optimized predictive model that achieved:</p>
  <ul>
      <li class="emoji">✅ <b>95% accuracy</b> on the training set</li>
      <li class="emoji">✅ <b>93.4% accuracy</b> on the test set</li>
  </ul>

  <h2 class="emoji">💡 What makes this project stand out?</h2>
  <p>Unlike conventional methods, I dedicated <b>extensive hours</b> to <b>custom data cleaning</b> by implementing self-developed algorithms, ensuring a <b>higher quality dataset</b> for training. Given the inherent inconsistencies in the raw dataset, my approach significantly improved model performance and reduced data bias.</p>

  <h2 class="emoji">📊 Dataset Overview</h2>
  <ul>
      <li class="emoji"><b>140,000+ records</b> with mental health-related features</li>
      <li class="emoji">High noise levels & inconsistencies required deep cleaning</li>
      <li class="emoji">Complex categorical & numerical features demanding transformation</li>
  </ul>

  <p><span class="emoji">⚡</span> <b>Data cleaning was a major challenge</b>, consuming a significant portion of the project timeline. Rather than using standard methods, I implemented <b>custom algorithms</b> to automate and refine:</p>
  <ul>
      <li class="emoji">✅ Missing value imputation with pattern-based logic</li>
      <li class="emoji">✅ Outlier detection & removal using statistical thresholds</li>
      <li class="emoji">✅ Standardization & normalization for better model convergence</li>
      <li class="emoji">✅ Encoding categorical variables dynamically to enhance feature usability</li>
  </ul>

  <h2 class="emoji">🔥 Tech Stack & Libraries Used</h2>
  <ul>
      <li class="emoji">🛠 <b>Frameworks & Tools:</b></li>
      <li>TensorFlow – Core deep learning framework</li>
      <li>Keras Tuner – Hyperparameter tuning for model optimization</li>
      <li>scikit-learn – Feature engineering, mutual_info_classif, train_test_split</li>
      <li>Pandas & NumPy – Custom-built data preprocessing algorithms</li>
      <li>Matplotlib & Seaborn – Visual analytics for understanding dataset distributions</li>
      <li>Kaggle API – Dataset handling & experimentation</li>
  </ul>

  <h2 class="emoji">⚙️ Model Development & Optimization</h2>

  <h3 class="emoji">🏗 Step 1: Exploratory Data Analysis (EDA)</h3>
  <ul>
      <li>Conducted in-depth statistical analysis</li>
      <li>Built visualization reports using Seaborn & Matplotlib</li>
      <li>Identified patterns & correlations for feature engineering</li>
  </ul>

  <h3 class="emoji">✨ Step 2: Data Cleaning & Feature Engineering</h3>
  <ul>
      <li>Extensively worked on data cleaning – Developed custom algorithms to handle missing values & inconsistencies</li>
      <li>Applied mutual_info_classif for feature selection</li>
      <li>Standardized data using scaling techniques</li>
  </ul>

  <h3 class="emoji">🏋️ Step 3: Model Training & Hyperparameter Tuning</h3>
  <ul>
      <li>🔹 Built multiple versions of the model, testing various architectures</li>
      <li>🔹 Used Keras Tuner for hyperparameter optimization</li>
      <li>🔹 Addressed computational constraints due to Kaggle GPU limits</li>
  </ul>

  <h3 class="emoji">📈 Step 4: Performance Evaluation</h3>
  <ul>
      <li class="emoji">✅ Achieved <b>95% accuracy</b> on training data</li>
      <li class="emoji">✅ Final model <b>93.4% accuracy</b> on test data</li>
      <li class="emoji">✅ Fine-tuned loss functions & learning rates for better convergence</li>
  </ul>

  <h2 class="emoji">🏆 Project Iterations & Notebook Versions</h2>
  <p>📌 This project underwent <b>8 iterations</b>, with each version refining performance and addressing computational challenges.</p>
  <p>🔗 <b>Explore my Kaggle Notebook here:</b> <a href="https://www.kaggle.com/code/ashwinashok55/mental-health-data-model">Mental Health Data Model 2</a>
  and here <a href="https://www.kaggle.com/code/ashwinashok55/mental-health-nn-model">Mental Health Data Model 1</a></p>

  <h2 class="emoji">🎯 Final Thoughts</h2>
  <p>This project was not just about training a deep learning model—it was a <b>battle against raw, unstructured, and inconsistent data</b>. By investing extensive hours in cleaning and refining the dataset, I ensured that the models were trained on <b>quality data, not noise</b>.</p>

  <p><span class="emoji">🚀</span> This journey strengthened my expertise in <b>data preprocessing, feature engineering, and deep learning</b>, making it a significant milestone in my <b>AI & Data Science</b> career.</p>

  <h3 class="emoji">🔍 If you're interested in collaborating or discussing the project, feel free to reach out!</h3>

</body>
</html>
